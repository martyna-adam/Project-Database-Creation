{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a database for crime reports \n",
    "\n",
    "In this project, the aim is to build a database for storing data related to crimes that have occured in Boston. \n",
    "\n",
    "The key Postgres skills in this project will be:\n",
    "* Creating a database and managing database roles\n",
    "* Creating a database schema and tables with proper datatypes\n",
    "* Loading data from csv files into database tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connecting to the database and creating a new database called crime_db \n",
    "conn = psycopg2.connect(dbname = 'dq', user = 'dq')\n",
    "cur = conn.cursor()\n",
    "conn.autocommit = True\n",
    "cur.execute(\"CREATE DATABASE crime_db;\")\n",
    "conn.autocommit = False \n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connecting to the new crime_db database and creating a new schema\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname = 'crime_db', user = 'dq')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE SCHEMA crimes;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Commiting the changes made\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Column Names and Sample\n",
    "Now we have a database and a scheme, we can start creating some tables. Before we can create tables, we need to have a look at a sample of the data to be able to select the correct datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the csv file\n",
    "import csv \n",
    "with open('boston.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    reader = list(reader)\n",
    "    col_headers = reader[0]\n",
    "    first_row = reader[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header data:  ['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "\n",
      "\n",
      "First row of data:  ['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "# Printing the header and the first row \n",
    "print('Header data: ', col_headers)\n",
    "print('\\n')\n",
    "print('First row of data: ', first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Auxiliary Function \n",
    "Before we create the table to store crime data, we need to identify the correct datatypes for the columns. To help us do this, we can create a helper function, which will compute a Python set with distinct values of a column, given the file name and column index. \n",
    "\n",
    "This function will help us to:\n",
    "* Check if an enumerated datatype could be used to represent a column \n",
    "* Compute the maximum length of any text in a column to enable the correct selection of size for VARCHAR to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number\t298329\n",
      "offense_code\t219\n",
      "description\t239\n",
      "date\t1177\n",
      "day_of_the_week\t7\n",
      "lat\t18177\n",
      "long\t18177\n"
     ]
    }
   ],
   "source": [
    "# Creating a helper function to find the number of different values of each column\n",
    "def get_col_set(csv_filename, col_index):\n",
    "    import csv\n",
    "    values = set()\n",
    "    with open(csv_filename, 'r') as file:\n",
    "        next(file)\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            values.add(row[col_index])\n",
    "    return values\n",
    "\n",
    "for row in range(len(col_headers)):\n",
    "    lengths = get_col_set('boston.csv', row)\n",
    "    print(col_headers[row], len(lengths), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the maximum length\n",
    "It would be useful to know the longest word in any column which contains text data. The two columns that contain text data are 'description' and 'day_of_the_week'. 'day_of_the_week' has seven values, so it's easy to compute the max length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "\n",
      "\n",
      "Maximum length of the description column is:  58\n"
     ]
    }
   ],
   "source": [
    "# printing value of col_headers to see what index the description column has\n",
    "print(col_headers)\n",
    "print('\\n')\n",
    "\n",
    "# using index to compute the length of the max description \n",
    "desc_colum = get_col_set('boston.csv', 2)\n",
    "max_length = 0\n",
    "for row in desc_colum:\n",
    "    max_length = max(max_length, len(row))\n",
    "\n",
    "print(\"Maximum length of the description column is: \", max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating the table\n",
    "Now we are ready to create the Boston Crimes table inside of the crimes schema. The day_of_the_week column is suitable for enumerated datatype as it only has 7 unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an enumerated datatype \n",
    "cur.execute(\"CREATE TYPE days_enum AS ENUM('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday');\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "\n",
      "\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "# Finding suitable column names for the table\n",
    "print(col_headers)\n",
    "print('\\n')\n",
    "\n",
    "# Reminding ourselves of the data contained in the file to help determine the correct datatype\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table column names will be the same as the column headers of the csv file. We will write out date as offence_date and latitude and longitude in full for ease of readability. The columns will have the following datatypes based on findings of unique values and max lengths:\n",
    "\n",
    "* incident_number = integer. This will also be the Primary Key for the table\n",
    "* offence_code = smallint\n",
    "* description = varchar(100)\n",
    "* offence_date = date \n",
    "* day_of_week = days_enum \n",
    "* latitude = decimal(10,8)\n",
    "* longitude = decimal(11,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_query = '''\n",
    "        CREATE TABLE crimes.boston_crimes (\n",
    "        incident_number integer PRIMARY KEY, \n",
    "        offence_code smallint,\n",
    "        description varchar(100),\n",
    "        offence_date date,\n",
    "        day_of_week days_enum,\n",
    "        latitude decimal(10,8),\n",
    "        longitude decimal(11,8));\n",
    "'''\n",
    "cur.execute(table_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Commiting the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "Now that we have the boston_crimes table, we can load data into it. In this project, we will use the cursor.copy_expert() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from the csv file into the new postgres table\n",
    "with open('boston.csv', 'r') as file:\n",
    "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 619, 'LARCENY ALL OTHERS', datetime.date(2018, 9, 2), 'Sunday', Decimal('42.35779134'), Decimal('-71.13937053')), (2, 1402, 'VANDALISM', datetime.date(2018, 8, 21), 'Tuesday', Decimal('42.30682138'), Decimal('-71.06030035')), (3, 3410, 'TOWED MOTOR VEHICLE', datetime.date(2018, 9, 3), 'Monday', Decimal('42.34658879'), Decimal('-71.07242943')), (4, 3114, 'INVESTIGATE PROPERTY', datetime.date(2018, 9, 3), 'Monday', Decimal('42.33418175'), Decimal('-71.07866441')), (5, 3114, 'INVESTIGATE PROPERTY', datetime.date(2018, 9, 3), 'Monday', Decimal('42.27536542'), Decimal('-71.09036101')), (6, 3820, 'M/V ACCIDENT INVOLVING PEDESTRIAN - INJURY', datetime.date(2018, 9, 3), 'Monday', Decimal('42.29019621'), Decimal('-71.07159012')), (7, 724, 'AUTO THEFT', datetime.date(2018, 9, 3), 'Monday', Decimal('42.30607218'), Decimal('-71.08273260')), (8, 3301, 'VERBAL DISPUTE', datetime.date(2018, 9, 3), 'Monday', Decimal('42.32701648'), Decimal('-71.10555088')), (9, 301, 'ROBBERY - STREET', datetime.date(2018, 9, 3), 'Monday', Decimal('42.33152148'), Decimal('-71.07085307')), (10, 3301, 'VERBAL DISPUTE', datetime.date(2018, 9, 3), 'Monday', Decimal('42.29514664'), Decimal('-71.05860832'))]\n"
     ]
    }
   ],
   "source": [
    "# Viewing if data loaded correctly     \n",
    "cur.execute(\"SELECT * FROM crimes.boston_crimes LIMIT 10;\")\n",
    "data = cur.fetchall()\n",
    "\n",
    "print(data, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revoking Public Privileges\n",
    "Now that we have a database and a scheme, we need to create two groups and follow the least privilege principle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# revoking all the privileges of the public group on the public schema\n",
    "\n",
    "cur.execute(\"REVOKE ALL ON SCHEMA public FROM public;\")\n",
    "\n",
    "# revoking all privileges of the public group on the crime_db database\n",
    "cur.execute(\"REVOKE ALL ON DATABASE crime_db FROM public;\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating User Groups \n",
    "In the previous step, we made sure that the new groups don't inadvertently inherit privileges from the public group. Now we can create the two new groups; readonly and readwrite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new user groups\n",
    "cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
    "\n",
    "cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
    "\n",
    "# Granting connect and usage privileges to the users\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readonly;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
    "\n",
    "# Granting specific privileges to each group on all tables\n",
    "cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT SELECT, INSERT, DELETE, UPDATE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Users \n",
    "Now that we have groups which have the correct privileges, we can create specific users. We will create two users, one for each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data_analyst user\n",
    "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
    "cur.execute(\"GRANT readonly TO data_analyst;\")\n",
    "\n",
    "# creating data_scientist user\n",
    "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
    "cur.execute(\"GRANT readwrite TO data_scientist;\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing \n",
    "The Postgres database is now set up! We can write some queries to perform test and ensure that the database has been set up correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dq', True, True, True, True, True, True, True, -1, '********', None, None, 10), ('readonly', False, True, False, False, False, False, False, -1, '********', None, None, 16415), ('readwrite', False, True, False, False, False, False, False, -1, '********', None, None, 16416), ('data_analyst', False, True, False, False, False, True, False, -1, '********', None, None, 16417), ('data_scientist', False, True, False, False, False, True, False, -1, '********', None, None, 16418)]\n",
      "\n",
      "\n",
      "[('readonly', 'SELECT'), ('readwrite', 'INSERT'), ('readwrite', 'SELECT'), ('readwrite', 'UPDATE'), ('readwrite', 'DELETE')]\n"
     ]
    }
   ],
   "source": [
    "# Querying the internal pg_roles table\n",
    "cur.execute(\"SELECT * FROM pg_roles;\")\n",
    "result = cur.fetchall()\n",
    "print(result)\n",
    "print('\\n')\n",
    "\n",
    "# Querying the internal information_schema.table_provileges table\n",
    "\n",
    "cur.execute(\"SELECT grantee, privilege_type FROM information_schema.table_privileges WHERE grantee = 'readonly' OR grantee = 'readwrite';\")\n",
    "result2 = cur.fetchall()\n",
    "print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
